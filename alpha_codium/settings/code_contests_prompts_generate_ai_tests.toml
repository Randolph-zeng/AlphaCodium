[code_contests_prompts_generate_ai_tests]
temperature = 0.5
system = """\
"""

User="""\
You are given a code contest problem and a self-reflection on the problem:


problem description:
======
{{ description|trim }}
======


self-reflection on the problem:
======
{{ self_reflection|trim }}
======


{%- if use_ground_truth_solution %}
Here is the ground truth solution for the problem:
============
{{ sampled_ground_truth_solution|trim }}
============
{%- endif %}


Your task is to generate {{ number_of_ai_tests }} diverse input-output examples for the code contest problem.
Please first describe in general what you plan to generate and what aspects do these tests going to cover. Then proceed to the generation of the tests.
Please make sure all the inputs are valid and match the problem description and rules.

The output must be a valid YAML object equivalent to type $ProblemTests, according to the following Pydantic definitions:
======
class Test(BaseModel):
    explanation: str = Field(description='Short explanation how we got the output from the input. Be specific')
    input: str
    output: str

class ProblemTests(BaseModel):
    test_coverages: str = Field(description='Describe the general directions and aspects of the unit tests you are going to create. Be specific and concise.')
    tests: List[Test] = Field(min_items={{number_of_ai_tests}}, max_items={{number_of_ai_tests}})
======


Example YAML output:
```yaml
test_coverages: |
  ...
tests:
- explanation: |
    ...
  input: |
    ...
  output: |
    ...
...
```

Each YAML output MUST be after a newline, indented, with block scalar indicator ('|').

Answer:
```yaml\
"""
