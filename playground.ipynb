{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Server Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Define the data payload as a Python dictionary\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/dataset/pretrained-models/deepseek-coder-7b-instruct-v1.5/\")\n",
    "messages_list = [\n",
    "    [{\"role\": \"user\", \"content\": \"Who are you?\"}],\n",
    "    [{\"role\": \"user\", \"content\": \"What can you do?\"}],\n",
    "    [{\"role\": \"user\", \"content\": \"Explain Transformer briefly.\"}],\n",
    "]\n",
    "prompts = [tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False) for messages in messages_list]\n",
    "data = {\n",
    "    \"prompt\": prompts,\n",
    "    \"model\": \"/dataset/pretrained-models/deepseek-coder-7b-instruct-v1.5/\",\n",
    "    \"temperature\":0.7, \n",
    "    \"top_p\":0.9, \n",
    "    \"max_tokens\":100\n",
    "}\n",
    "\n",
    "# Convert the Python dictionary to a JSON string\n",
    "data_json = json.dumps(data)\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post('http://10.81.200.23:10245/v1/completions', \n",
    "                        headers={'Content-Type': 'application/json'}, \n",
    "                        data=data_json)\n",
    "response.json()['choices'][0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92mlitellm.completion(model='openai//dataset/pretrained-models/deepseek-coder-33b-instruct/', api_key='sk-1234', api_base='http://0.0.0.0:10245/v1', messages=[{'role': 'user', 'content': \"Hey, how's it going?\"}])\u001b[0m\n",
      "\n",
      "\n",
      "self.optional_params: {}\n",
      "kwargs[caching]: False; litellm.cache: None\n",
      "UNMAPPED PROVIDER, ASSUMING IT'S OPENAI/AZURE\n",
      "Final returned optional params: {'extra_body': {}}\n",
      "self.optional_params: {'extra_body': {}}\n",
      "\u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "http://0.0.0.0:10245/v1/ \\\n",
      "-d '{'model': '/dataset/pretrained-models/deepseek-coder-33b-instruct/', 'messages': [{'role': 'user', 'content': \"Hey, how's it going?\"}], 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"cmpl-88b7d510b7c741989ffbd5532dcf7359\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"Hello! As an AI, I don't have feelings, but thank you for asking. How can I assist you with your programming or computer science needs today?\\n\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null}}], \"created\": 3015748, \"model\": \"/dataset/pretrained-models/deepseek-coder-33b-instruct/\", \"object\": \"chat.completion\", \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 35, \"prompt_tokens\": 77, \"total_tokens\": 112}}\n",
      "\n",
      "\n",
      "Logging Details LiteLLM-Success Call: None\n",
      "Looking up model=/dataset/pretrained-models/deepseek-coder-33b-instruct/ in model_cost_map\n",
      "success callbacks: []\n",
      "{'id': 'cmpl-88b7d510b7c741989ffbd5532dcf7359', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': \"Hello! As an AI, I don't have feelings, but thank you for asking. How can I assist you with your programming or computer science needs today?\\n\", 'role': 'assistant'}}], 'created': 3015748, 'model': '/dataset/pretrained-models/deepseek-coder-33b-instruct/', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': {'completion_tokens': 35, 'prompt_tokens': 77, 'total_tokens': 112}}\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "import os\n",
    "litellm.set_verbose=True\n",
    "# model = \"openai//dataset/pretrained-models/deepseek-coder-7b-instruct-v1.5/\"\n",
    "model = \"openai//dataset/pretrained-models/deepseek-coder-33b-instruct/\"\n",
    "response = litellm.completion(\n",
    "    model=model,               # add `openai/` prefix to model so litellm knows to route to OpenAI\n",
    "    api_key=\"sk-1234\",                  # api key to your openai compatible endpoint\n",
    "    api_base=\"http://0.0.0.0:10245/v1\",     # set API Base of your Custom OpenAI Endpoint\n",
    "    messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Hey, how's it going?\",\n",
    "                }\n",
    "    ],\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
